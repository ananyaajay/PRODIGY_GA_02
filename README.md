# PRODIGY_GA_02

# IMAGE GENERATION WITH PRE-TRAINED MODELS ðŸ¤–

Pre-trained generative models like DALL-E-mini or Stable Diffusion to create images from text prompts. This code generates an image from a text prompt using the Stable Diffusion model via Hugging Faceâ€™s Diffusers library. It automatically selects GPU or CPU for processing, loads a pre-trained model, creates art based on a prompt, and saves the result as an image file. 

## âœ“ Features: 
â€¢ Text-to-image generation Automatic device selection (GPU/CPU) 

â€¢ Model loading from Hugging Face Image saving capability

## âœ“ Concepts Used: 
â€¢ Deep learning (text-to-image diffusion models) 

â€¢ PyTorch device handling Model inference File I/O 

## âœ“ Highlights: 
â€¢ Simplicity and clarity 

â€¢ Flexible hardware support 

â€¢ Extensible for custom prompts or models
